{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Configuration"
   ],
   "metadata": {
    "id": "HT7f-wW5_Ctn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pydicom\n",
    "!pip install optuna\n",
    "!pip install scikit-image"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f73hkk1kUr3x",
    "outputId": "0e58cd33-d5b1-4c50-b3a0-ad7d9ea1c9f1",
    "ExecuteTime": {
     "end_time": "2025-02-01T16:43:41.421023400Z",
     "start_time": "2025-02-01T16:43:11.110181300Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in e:\\00my workspace\\my_venv\\lib\\site-packages (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in e:\\00my workspace\\my_venv\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in e:\\00my workspace\\my_venv\\lib\\site-packages (from optuna) (2.0.30)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\00my workspace\\my_venv\\lib\\site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: PyYAML in e:\\00my workspace\\my_venv\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: colorlog in e:\\00my workspace\\my_venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in e:\\00my workspace\\my_venv\\lib\\site-packages (from optuna) (1.14.0)\n",
      "Requirement already satisfied: numpy in e:\\00my workspace\\my_venv\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: tqdm in e:\\00my workspace\\my_venv\\lib\\site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in e:\\00my workspace\\my_venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: Mako in e:\\00my workspace\\my_venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\00my workspace\\my_venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.3)\n",
      "Requirement already satisfied: colorama in e:\\00my workspace\\my_venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in e:\\00my workspace\\my_venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.25.1-cp310-cp310-win_amd64.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 10.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.24 in e:\\00my workspace\\my_venv\\lib\\site-packages (from scikit-image) (1.24.3)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\00my workspace\\my_venv\\lib\\site-packages (from scikit-image) (3.3)\n",
      "Collecting pillow>=10.1\n",
      "  Downloading pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 8.8 MB/s eta 0:00:00\n",
      "Collecting lazy-loader>=0.4\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2025.1.10-py3-none-any.whl (227 kB)\n",
      "     ------------------------------------- 227.6/227.6 kB 13.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=21 in e:\\00my workspace\\my_venv\\lib\\site-packages (from scikit-image) (23.1)\n",
      "Collecting imageio!=2.35.0,>=2.33\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "     ------------------------------------- 315.8/315.8 kB 19.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.11.2 in e:\\00my workspace\\my_venv\\lib\\site-packages (from scikit-image) (1.11.2)\n",
      "Installing collected packages: tifffile, pillow, lazy-loader, imageio, scikit-image\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 10.0.1\n",
      "    Uninstalling Pillow-10.0.1:\n",
      "      Successfully uninstalled Pillow-10.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'E:\\\\00MY WORKSPACE\\\\my_venv\\\\Lib\\\\site-packages\\\\~il\\\\_imaging.cp310-win_amd64.pyd'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement torch==1.0.2 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\n",
      "ERROR: No matching distribution found for torch==1.0.2\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-01T16:45:52.493417700Z",
     "start_time": "2025-02-01T16:45:50.497659900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in e:\\00my workspace\\my_venv\\lib\\site-packages (11.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\00my workspace\\my_venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade Pillow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-01T16:46:53.202443Z",
     "start_time": "2025-02-01T16:46:48.229092300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pydicom\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage.transform import resize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "# Monter Google Drive avec force remount\n",
    "#drive.mount('/content/drive', force_remount=True)\n"
   ],
   "metadata": {
    "id": "W04bUOKR-ddo",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "outputId": "3623fe59-f0e6-43c4-b960-b016cd9b584d",
    "ExecuteTime": {
     "end_time": "2025-02-01T16:44:02.543585900Z",
     "start_time": "2025-02-01T16:44:02.425212Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#from skimage.transform import resize\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chargement du dataset"
   ],
   "metadata": {
    "id": "g2n5Ud6X_Jzl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def load_dicom_series(directory):\n",
    "    \"\"\"\n",
    "    Charge une série d'images DICOM à partir d'un dossier.\n",
    "    \"\"\"\n",
    "    dicom_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.dcm')]\n",
    "    dicom_files.sort()  # Assurez-vous que les fichiers sont dans le bon ordre\n",
    "    slices = [pydicom.dcmread(f) for f in dicom_files]\n",
    "    return slices\n",
    "\n",
    "def get_pixel_array(dicom_slices):\n",
    "    \"\"\"\n",
    "    Convertit une série de slices DICOM en un tableau numpy 3D.\n",
    "    \"\"\"\n",
    "    volume = np.stack([s.pixel_array for s in dicom_slices], axis=0)\n",
    "    return volume\n",
    "\n",
    "# Exemple d'utilisation\n",
    "#dicom_directory = \"/content/drive/MyDrive/Colab/ganglions_detection/dataset\"\n",
    "dicom_directory = \"/dataset\"\n",
    "dicom_slices = load_dicom_series(dicom_directory)\n",
    "volume = get_pixel_array(dicom_slices)\n",
    "print(\"Volume shape:\", volume.shape)"
   ],
   "metadata": {
    "id": "4zFRM0xB_Ww3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "outputId": "b948f039-a4ba-4596-8ad5-f485afbb9f0e",
    "ExecuteTime": {
     "end_time": "2025-02-01T16:42:02.592142800Z",
     "start_time": "2025-02-01T16:42:02.502617100Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: '/dataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotADirectoryError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Exemple d'utilisation\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#dicom_directory = \"/content/drive/MyDrive/Colab/ganglions_detection/dataset\"\u001B[39;00m\n\u001B[0;32m     19\u001B[0m dicom_directory \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/dataset\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 20\u001B[0m dicom_slices \u001B[38;5;241m=\u001B[39m \u001B[43mload_dicom_series\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdicom_directory\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m volume \u001B[38;5;241m=\u001B[39m get_pixel_array(dicom_slices)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVolume shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, volume\u001B[38;5;241m.\u001B[39mshape)\n",
      "Cell \u001B[1;32mIn[3], line 5\u001B[0m, in \u001B[0;36mload_dicom_series\u001B[1;34m(directory)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_dicom_series\u001B[39m(directory):\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m    Charge une série d'images DICOM à partir d'un dossier.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m     dicom_files \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory, f) \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.dcm\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[0;32m      6\u001B[0m     dicom_files\u001B[38;5;241m.\u001B[39msort()  \u001B[38;5;66;03m# Assurez-vous que les fichiers sont dans le bon ordre\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     slices \u001B[38;5;241m=\u001B[39m [pydicom\u001B[38;5;241m.\u001B[39mdcmread(f) \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m dicom_files]\n",
      "\u001B[1;31mNotADirectoryError\u001B[0m: [WinError 267] The directory name is invalid: '/dataset'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prétraitement"
   ],
   "metadata": {
    "id": "0aXjrNQF_YrV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def normalize_volume(volume):\n",
    "    \"\"\"\n",
    "    Normalise les intensités des pixels entre 0 et 1.\n",
    "    \"\"\"\n",
    "    volume = (volume - np.min(volume)) / (np.max(volume) - np.min(volume))\n",
    "    return volume\n",
    "\n",
    "def resize_volume(volume, target_shape):\n",
    "    \"\"\"\n",
    "    Redimensionne le volume à une taille cible.\n",
    "    \"\"\"\n",
    "    resized_volume = np.zeros(target_shape)\n",
    "    for i in range(volume.shape[0]):\n",
    "        resized_volume[i] = resize(volume[i], target_shape[1:], preserve_range=True)\n",
    "    return resized_volume\n",
    "\n",
    "# Exemple de prétraitement\n",
    "volume_normalized = normalize_volume(volume)\n",
    "target_shape = (volume.shape[0], 256, 256)  # Redimensionner à 256x256\n",
    "volume_resized = resize_volume(volume_normalized, target_shape)\n",
    "print(\"Volume resized shape:\", volume_resized.shape)"
   ],
   "metadata": {
    "id": "IQip5MkY34p_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cXxus0go_rVm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle"
   ],
   "metadata": {
    "id": "I1DpvrPI_sP6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création du modèle"
   ],
   "metadata": {
    "id": "Ha2vPHGkGIMj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder1 = self.conv_block(in_channels, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        # Decoder\n",
    "        self.decoder1 = self.conv_block(256, 128)\n",
    "        self.decoder2 = self.conv_block(128, 64)\n",
    "        self.final_layer = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        # Classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 1),  # Classification binaire\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.encoder1(x)\n",
    "        x2 = self.encoder2(F.max_pool2d(x1, 2))\n",
    "        x3 = self.encoder3(F.max_pool2d(x2, 2))\n",
    "        # Decoder\n",
    "        x = F.interpolate(x3, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        x = self.decoder1(x + x2)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        x = self.decoder2(x + x1)\n",
    "        segmentation = self.final_layer(x)\n",
    "        # Classification\n",
    "        classification = self.classifier(x3)\n",
    "        return segmentation, classification\n",
    "\n",
    "# Exemple d'initialisation du modèle\n",
    "model = UNet(in_channels=1, out_channels=1)\n",
    "print(model)"
   ],
   "metadata": {
    "id": "bztHDzwF-pb1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dummy_input = torch.rand((1, 1, 128, 128, 128)).to(device)\n",
    "output = model(dummy_input)\n",
    "print(\"Output Shape:\", output.shape)  # Devrait être (1, 1, 128, 128, 128)\n"
   ],
   "metadata": {
    "id": "kdcYhcYf-rMK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrainement du modèle"
   ],
   "metadata": {
    "id": "Y271pDCyGTsX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Fonction de perte\n",
    "def dice_loss(pred, target):\n",
    "    smooth = 1.\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    return 1 - (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n",
    "\n",
    "# Optimiseur\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(10):  # 10 époques\n",
    "    model.train()\n",
    "    for batch in dataloader:  # Remplacez par votre DataLoader\n",
    "        inputs, masks, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs, classifications = model(inputs)\n",
    "        loss_seg = dice_loss(outputs, masks)\n",
    "        loss_cls = F.binary_cross_entropy(classifications, labels)\n",
    "        loss = loss_seg + loss_cls\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ],
   "metadata": {
    "id": "ncyM9qqi-ukG",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "outputId": "2d0bb280-b0a4-4fc2-d027-f521c87a6ec6"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-86d8c668be8e>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;31m# Optimiseur\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.001\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;31m# Boucle d'entraînement\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation du modèle"
   ],
   "metadata": {
    "id": "MdpyrFoiAEm5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, val_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    dice_scores, iou_scores = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, masks = batch['image'].to(device), batch['mask'].to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = torch.sigmoid(outputs)  # Appliquer la sigmoid pour obtenir des probas\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                dice_scores.append(dice_score(outputs[i], masks[i], threshold))\n",
    "                iou_scores.append(iou_score(outputs[i], masks[i], threshold))\n",
    "\n",
    "    print(f\"⚡ Dice Score moyen : {np.mean(dice_scores):.4f}\")\n",
    "    print(f\"⚡ IoU moyen : {np.mean(iou_scores):.4f}\")\n",
    "\n",
    "# Lancer l'évaluation\n",
    "evaluate_model(model, val_loader)\n"
   ],
   "metadata": {
    "id": "-yJ3t-loANAF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "DGJZaXufAQKY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Optimisation du modèle"
   ],
   "metadata": {
    "id": "856yc7sfGpJP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # Entraînement et évaluation\n",
    "    return validation_loss  # Remplacez par votre métrique de validation\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"Meilleurs hyperparamètres:\", study.best_params)"
   ],
   "metadata": {
    "id": "eNnu4hnfGsY5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "kCit6jSPGvMs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prédiction du modèle"
   ],
   "metadata": {
    "id": "bZj9c9q1Gy6S"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def predict(model, input_volume):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor(input_volume).unsqueeze(0).unsqueeze(0).float()\n",
    "        segmentation, classification = model(input_tensor)\n",
    "        return segmentation.squeeze().numpy(), classification.item()\n",
    "\n",
    "# Exemple de prédiction\n",
    "segmentation_map, classification = predict(model, volume_resized[0])\n",
    "print(\"Classification:\", \"Pathologique\" if classification > 0.5 else \"Normal\")\n",
    "plt.imshow(segmentation_map, cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "1YGlNK67G5a8"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
